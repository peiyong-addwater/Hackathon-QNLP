{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f77042f-a3da-426e-980e-044b38949914",
   "metadata": {
    "tags": []
   },
   "source": [
    "# The QNLP Pipeline for Twitter Sentiment Analysis\n",
    "## 1. Load the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3824bba-eb18-4f46-bafa-4a670c427b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "from random import shuffle\n",
    "import random\n",
    "from discopy.tensor import Tensor\n",
    "from discopy import Word\n",
    "from discopy.rigid import Functor\n",
    "from discopy import grammar\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from jax import numpy as np\n",
    "import numpy\n",
    "from lambeq import AtomicType, IQPAnsatz, remove_cups, NumpyModel, spiders_reader\n",
    "from lambeq import BobcatParser, TreeReader, cups_reader, DepCCGParser, TreeReaderMode\n",
    "from lambeq import Dataset\n",
    "from lambeq import QuantumTrainer, SPSAOptimizer\n",
    "from lambeq import TketModel\n",
    "from lambeq import Rewriter\n",
    "from pytket.extensions.qiskit import AerBackend\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from pytket.circuit.display import render_circuit_jupyter\n",
    "\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.options.display.max_colwidth=80\n",
    "print(os.getcwd())\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "BATCH_SIZE = 50\n",
    "EPOCHS = 200\n",
    "SEED = 0\n",
    "\n",
    "TRAIN_INDEX_RATIO = 0.08\n",
    "VAL_INDEX_RATIO = TRAIN_INDEX_RATIO + 0.01\n",
    "TEST_INDEX_RATIO = VAL_INDEX_RATIO + 0.01\n",
    "\n",
    "\n",
    "assert TEST_INDEX_RATIO <= 1\n",
    "\n",
    "def load_pickled_dict_to_df(filename):\n",
    "    saved_dict = pickle.load(open(filename, 'rb'))\n",
    "    df =  pd.DataFrame.from_dict(saved_dict)\n",
    "    df =  df.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "    sentiment = []\n",
    "    for i in df['target']:\n",
    "        if i == \"Positive\":\n",
    "            sentiment.append(1)\n",
    "        else:\n",
    "            sentiment.append(0)\n",
    "    df[\"Sentiment\"] = sentiment\n",
    "    return df\n",
    "\n",
    "cleaned_qnlp_filename = os.path.join(os.getcwd(), 'cleaned_qnlp_data.pkl')\n",
    "cleaned_lemmatized_qnlp_filename = os.path.join(os.getcwd(), 'cleaned_qnlp_data_lematize.pkl')\n",
    "cleaned_lemmatized_stemmed_qnlp_filename = os.path.join(os.getcwd(), 'cleaned_qnlp_data_stem_lematize.pkl')\n",
    "\n",
    "cleaned_qnlp = load_pickled_dict_to_df(cleaned_qnlp_filename)\n",
    "\n",
    "cleaned_lemmatized_qnlp = load_pickled_dict_to_df(cleaned_lemmatized_qnlp_filename)\n",
    "\n",
    "cleaned__lemmatized_stemmed_qnlp = load_pickled_dict_to_df(cleaned_lemmatized_stemmed_qnlp_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a7efb9-18c0-4a8d-b3c1-93c149971571",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_qnlp.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7515c83a-1b10-4162-96ac-e1809637ad5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_qnlp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9761735-1ceb-4bfa-9584-8b88773a4d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = \"target\", data = cleaned_qnlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1b3ad8-e7aa-4045-8a9c-78dc26075823",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_lemmatized_qnlp.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc7b47f-d4cd-4694-8990-6ae7304a7757",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_lemmatized_qnlp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de851c0b-4e86-48d7-ba4e-11bd74b1bc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='target', data = cleaned_lemmatized_qnlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a635a65c-17ca-4e4d-888c-c564498bef7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned__lemmatized_stemmed_qnlp.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354d02dc-2c1d-4b8c-8242-8a6517b8a4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned__lemmatized_stemmed_qnlp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602f278c-407a-4ffd-8b6f-2a94bca1ef00",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='target', data = cleaned__lemmatized_stemmed_qnlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d67456-d626-4fb6-bb12-ec3210a13e9c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Train QNLP Models for Different-Preprocessed Data\n",
    "Since the limited parsing and training speed using on the CPU, we'll only use a fraction of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50766c20-c2f8-4fc2-974e-55c8e58fe93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = BobcatParser(verbose='text')\n",
    "# parser = DepCCGParser(root_cats=['S[dcl]'])\n",
    "# parser = spiders_reader\n",
    "parser = TreeReader(mode=TreeReaderMode.RULE_TYPE)\n",
    "NUM_DATA = 2578\n",
    "\n",
    "loss = lambda y_hat, y: -np.sum(y * np.log(y_hat)) / len(y)  # binary cross-entropy loss\n",
    "acc = lambda y_hat, y: np.sum(np.round(y_hat) == y) / len(y) / 2  # half due to double-counting\n",
    "rewriter = Rewriter(['prepositional_phrase', 'determiner', 'auxiliary', 'connector', \n",
    "                         'coordination', 'object_rel_pronoun', 'subject_rel_pronoun',\n",
    "                        'postadverb', 'preadverb'])\n",
    "def rewrite(diagram):\n",
    "    # diagram = rewriter(diagram)\n",
    "    return remove_cups(diagram)\n",
    "\n",
    "def create_diagrams_and_labels(total_df, NUM_DATA = 2578):\n",
    "    total_text = total_df['data'].tolist()\n",
    "    total_labels = total_df[\"Sentiment\"].tolist()\n",
    "    total_labels = [[t, 1-t] for t in total_labels] # [1, 0] for positive, [0, 1] for negative\n",
    "    train_diagrams = parser.sentences2diagrams(total_text[:round(NUM_DATA*TRAIN_INDEX_RATIO)])\n",
    "    train_labels = total_labels[:round(NUM_DATA*TRAIN_INDEX_RATIO)]\n",
    "    dev_diagrams = parser.sentences2diagrams(total_text[round(NUM_DATA*TRAIN_INDEX_RATIO):round(NUM_DATA*VAL_INDEX_RATIO)])\n",
    "    dev_labels = total_labels[round(NUM_DATA*TRAIN_INDEX_RATIO):round(NUM_DATA*VAL_INDEX_RATIO)]\n",
    "    test_diagrams = parser.sentences2diagrams(total_text[round(NUM_DATA*VAL_INDEX_RATIO):round(NUM_DATA*TEST_INDEX_RATIO)])\n",
    "    test_labels = total_labels[round(NUM_DATA*VAL_INDEX_RATIO):round(NUM_DATA*TEST_INDEX_RATIO)]\n",
    "    \n",
    "    return train_diagrams, train_labels, dev_diagrams, dev_labels, test_diagrams, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c0bcd7-f858-4220-b075-3152bbf85f7c",
   "metadata": {},
   "source": [
    "### 2.1 Data with both Lemmatization and Stemming\n",
    "#### 2.1.1 Create diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4a142e-a3bc-4f32-a45a-fc07c1a14262",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cleaned__lemmatized_stemmed_qnlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f9920d-de6f-4410-809c-2c83e7dac786",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_train_diagrams_1, train_labels_1, raw_dev_diagrams_1, dev_labels_1, raw_test_diagrams_1, test_labels_1 = create_diagrams_and_labels(data)\n",
    "print(len(raw_train_diagrams_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278401ec-572d-4e40-aa44-0df5663944ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_diagrams_1[0].draw(figsize=(12,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f23dd5a-d9ae-42af-8d49-eeae1b447586",
   "metadata": {},
   "source": [
    "#### 2.1.2 Simplify the diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055c1f6c-1a18-47b7-8b9f-02d45f9d5f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_diagrams_1 = [rewrite(diagram) for diagram in raw_train_diagrams_1]\n",
    "dev_diagrams_1 = [rewrite(diagram) for diagram in raw_dev_diagrams_1]\n",
    "test_diagrams_1 = [rewrite(diagram) for diagram in raw_test_diagrams_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2e5e72-2a43-4de2-93fc-88f9b890511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_diagrams_1[0].draw(figsize=(6,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea04f63-d585-4306-b62f-942dc847e20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "alternate_parser = BobcatParser(verbose='text')\n",
    "dig_0 = alternate_parser.sentence2diagram(cleaned__lemmatized_stemmed_qnlp['data'].tolist()[0])\n",
    "grammar.draw(dig_0, figsize=(14,3), fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c33c912-81e7-4a98-ad27-01ecb112dc33",
   "metadata": {},
   "source": [
    "#### 2.1.3 Create circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23573aa4-3a07-43d0-b1b4-2e6c6b10b244",
   "metadata": {},
   "outputs": [],
   "source": [
    "ansatz_1 = IQPAnsatz({AtomicType.NOUN: 1, AtomicType.SENTENCE: 1, AtomicType.PREPOSITIONAL_PHRASE: 1, AtomicType.NOUN_PHRASE:1, AtomicType.CONJUNCTION:1}, n_layers=1, n_single_qubit_params=3)\n",
    "train_circuits_1 = [ansatz_1(diagram) for diagram in train_diagrams_1]\n",
    "dev_circuits_1 =  [ansatz_1(diagram) for diagram in dev_diagrams_1]\n",
    "test_circuits_1 = [ansatz_1(diagram) for diagram in test_diagrams_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642347ed-1491-4ea5-a5c3-5ee0dc8ed478",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_circuits_1[0].draw(figsize=(9, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba0503c-1561-4f55-84e3-4eb9738079cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_circuits_1[0].draw(figsize=(9, 12))\n",
    "render_circuit_jupyter(train_circuits_1[0].to_tk())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0310ad5b-4e50-4187-b13b-f9500c812eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "[(s, s.size) for s in train_circuits_1[0].free_symbols]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b774c35-5065-4cae-bcfd-ecf1e2b29c4e",
   "metadata": {},
   "source": [
    "#### 2.1.4 Parameterise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37bf884-8e1f-4f47-b2b0-047708bbe52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_circuits_1 = train_circuits_1 + dev_circuits_1 + test_circuits_1\n",
    "model_1 = NumpyModel.from_diagrams(all_circuits_1, use_jit=True)\n",
    "# model_1 = TketModel.from_diagrams(all_circuits_1, backend_config=backend_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3bcb48-cf2a-46dd-96ca-1b4b46646a42",
   "metadata": {},
   "source": [
    "#### 2.1.5 Initialize trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7468b472-f23e-47fb-887c-069334944174",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_1 = QuantumTrainer(\n",
    "    model_1,\n",
    "    loss_function=loss,\n",
    "    epochs=EPOCHS,\n",
    "    optimizer=SPSAOptimizer,\n",
    "    optim_hyperparams={'a': 0.2, 'c': 0.06, 'A':0.01*EPOCHS},\n",
    "    evaluate_functions={'acc': acc},\n",
    "    evaluate_on_train=True,\n",
    "    verbose = 'text',\n",
    "    seed=0\n",
    ")\n",
    "train_dataset_1 = Dataset(\n",
    "            train_circuits_1,\n",
    "            train_labels_1,\n",
    "            batch_size=BATCH_SIZE)\n",
    "\n",
    "val_dataset_1 = Dataset(dev_circuits_1, dev_labels_1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013379f2-1532-414f-9fe8-c2d751367750",
   "metadata": {},
   "source": [
    "#### 2.1.6 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55858d6-b168-4482-a06b-f6a13003e391",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer_1.fit(train_dataset_1, val_dataset_1, logging_step=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73e1171-7877-40c5-ae59-c8822c5689c8",
   "metadata": {},
   "source": [
    "#### 2.1.7 Show Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8670eb81-c4c8-43c5-ab8a-c78d7f37fd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax_tl, ax_tr), (ax_bl, ax_br)) = plt.subplots(2, 2, sharex=True, sharey='row', figsize=(12, 8))\n",
    "ax_tl.set_title('Training set')\n",
    "ax_tr.set_title('Development set')\n",
    "ax_bl.set_xlabel('Iterations')\n",
    "ax_br.set_xlabel('Iterations')\n",
    "ax_bl.set_ylabel('Accuracy')\n",
    "ax_tl.set_ylabel('Loss')\n",
    "\n",
    "colours = iter(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n",
    "ax_tl.plot(trainer_1.train_epoch_costs, color=next(colours))\n",
    "ax_bl.plot(trainer_1.train_results['acc'], color=next(colours))\n",
    "ax_tr.plot(trainer_1.val_costs, color=next(colours))\n",
    "ax_br.plot(trainer_1.val_results['acc'], color=next(colours))\n",
    "\n",
    "test_acc_1 = acc(model_1(test_circuits_1), test_labels_1)\n",
    "#print('Test accuracy:', test_acc_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a92b742-73e9-498c-9be7-f2d5b09c1b72",
   "metadata": {},
   "source": [
    "### 2.2 Data with only Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7db859-f9a9-4068-a8fc-9cb170d7697f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cleaned_lemmatized_qnlp\n",
    "raw_train_diagrams_1, train_labels_1, raw_dev_diagrams_1, dev_labels_1, raw_test_diagrams_1, test_labels_1 = create_diagrams_and_labels(data)\n",
    "print(len(raw_train_diagrams_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0743ab22-8ec7-4f65-8455-3f14cdd5e1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_diagrams_1[0].draw(figsize=(12,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069de9d4-04cb-4a3c-9632-9a17ce415d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_diagrams_1 = [rewrite(diagram) for diagram in raw_train_diagrams_1]\n",
    "dev_diagrams_1 = [rewrite(diagram) for diagram in raw_dev_diagrams_1]\n",
    "test_diagrams_1 = [rewrite(diagram) for diagram in raw_test_diagrams_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478bd6c7-13a6-4b1c-8c48-3ef01089e946",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_diagrams_1[0].draw(figsize=(6,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c586268-b667-42f3-ba19-85118d31cd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "ansatz_1 = IQPAnsatz({AtomicType.NOUN: 1, AtomicType.SENTENCE: 1, AtomicType.PREPOSITIONAL_PHRASE: 1, AtomicType.NOUN_PHRASE:1, AtomicType.CONJUNCTION:1}, n_layers=1, n_single_qubit_params=3)\n",
    "train_circuits_1 = [ansatz_1(diagram) for diagram in train_diagrams_1]\n",
    "dev_circuits_1 =  [ansatz_1(diagram) for diagram in dev_diagrams_1]\n",
    "test_circuits_1 = [ansatz_1(diagram) for diagram in test_diagrams_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8881ee7-6ef2-473b-9e2a-f4df591c3f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_circuits_1[0].draw(figsize=(9, 12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6cecc9-d496-47e5-b09a-0b4a00ddbb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "render_circuit_jupyter(train_circuits_1[0].to_tk())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72df6b0e-a008-42a5-b69f-aafaa5f0d9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_circuits_1 = train_circuits_1 + dev_circuits_1 + test_circuits_1\n",
    "model_1 = NumpyModel.from_diagrams(all_circuits_1, use_jit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42df4394-c1c8-4f64-ad68-4f3969792cad",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_1 = QuantumTrainer(\n",
    "    model_1,\n",
    "    loss_function=loss,\n",
    "    epochs=EPOCHS,\n",
    "    optimizer=SPSAOptimizer,\n",
    "    optim_hyperparams={'a': 0.2, 'c': 0.06, 'A':0.01*EPOCHS},\n",
    "    evaluate_functions={'acc': acc},\n",
    "    evaluate_on_train=True,\n",
    "    verbose = 'text',\n",
    "    seed=0\n",
    ")\n",
    "train_dataset_1 = Dataset(\n",
    "            train_circuits_1,\n",
    "            train_labels_1,\n",
    "            batch_size=BATCH_SIZE)\n",
    "\n",
    "val_dataset_1 = Dataset(dev_circuits_1, dev_labels_1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a27c4b0-140a-4cbc-81df-bfb8e1225464",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer_1.fit(train_dataset_1, val_dataset_1, logging_step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fb0f09-d7bc-4122-8517-fc7b2b5310d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax_tl, ax_tr), (ax_bl, ax_br)) = plt.subplots(2, 2, sharex=True, sharey='row', figsize=(12, 8))\n",
    "ax_tl.set_title('Training set')\n",
    "ax_tr.set_title('Development set')\n",
    "ax_bl.set_xlabel('Iterations')\n",
    "ax_br.set_xlabel('Iterations')\n",
    "ax_bl.set_ylabel('Accuracy')\n",
    "ax_tl.set_ylabel('Loss')\n",
    "\n",
    "colours = iter(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n",
    "ax_tl.plot(trainer_1.train_epoch_costs, color=next(colours))\n",
    "ax_bl.plot(trainer_1.train_results['acc'], color=next(colours))\n",
    "ax_tr.plot(trainer_1.val_costs, color=next(colours))\n",
    "ax_br.plot(trainer_1.val_results['acc'], color=next(colours))\n",
    "\n",
    "test_acc_1 = acc(model_1(test_circuits_1), test_labels_1)\n",
    "#print('Test accuracy:', test_acc_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109ddf2f-b42e-4e5c-a103-493aa37c8c59",
   "metadata": {},
   "source": [
    "### 2.3 Data without Lemmatization or stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0146ce58-9962-489a-abe6-7b1c91cc5ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cleaned_qnlp\n",
    "raw_train_diagrams_1, train_labels_1, raw_dev_diagrams_1, dev_labels_1, raw_test_diagrams_1, test_labels_1 = create_diagrams_and_labels(data)\n",
    "print(len(raw_train_diagrams_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41608ed1-d00b-42b4-a601-889b2e251579",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_diagrams_1[0].draw(figsize=(12,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba532073-94fc-4570-bf7e-f48a530f01ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_diagrams_1 = [rewrite(diagram) for diagram in raw_train_diagrams_1]\n",
    "dev_diagrams_1 = [rewrite(diagram) for diagram in raw_dev_diagrams_1]\n",
    "test_diagrams_1 = [rewrite(diagram) for diagram in raw_test_diagrams_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c419336-8ea5-4aec-8e5c-80787d38eb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_diagrams_1[0].draw(figsize=(6,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b6bb8d-634e-4687-9c5f-f3f9f6de27cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "render_circuit_jupyter(train_circuits_1[0].to_tk())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a78c101-65f8-47f5-8893-bca55bb2c05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_circuits_1 = train_circuits_1 + dev_circuits_1 + test_circuits_1\n",
    "model_1 = NumpyModel.from_diagrams(all_circuits_1, use_jit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabba0d0-fdaf-4d34-99ba-55962052620d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_1 = QuantumTrainer(\n",
    "    model_1,\n",
    "    loss_function=loss,\n",
    "    epochs=EPOCHS,\n",
    "    optimizer=SPSAOptimizer,\n",
    "    optim_hyperparams={'a': 0.2, 'c': 0.06, 'A':0.01*EPOCHS},\n",
    "    evaluate_functions={'acc': acc},\n",
    "    evaluate_on_train=True,\n",
    "    verbose = 'text',\n",
    "    seed=0\n",
    ")\n",
    "train_dataset_1 = Dataset(\n",
    "            train_circuits_1,\n",
    "            train_labels_1,\n",
    "            batch_size=BATCH_SIZE)\n",
    "\n",
    "val_dataset_1 = Dataset(dev_circuits_1, dev_labels_1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c912f59a-cb57-4c45-9e84-05fa30966dde",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer_1.fit(train_dataset_1, val_dataset_1, logging_step=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf9c328-fa77-4598-8646-c4020d85d17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax_tl, ax_tr), (ax_bl, ax_br)) = plt.subplots(2, 2, sharex=True, sharey='row', figsize=(12, 8))\n",
    "ax_tl.set_title('Training set')\n",
    "ax_tr.set_title('Development set')\n",
    "ax_bl.set_xlabel('Iterations')\n",
    "ax_br.set_xlabel('Iterations')\n",
    "ax_bl.set_ylabel('Accuracy')\n",
    "ax_tl.set_ylabel('Loss')\n",
    "\n",
    "colours = iter(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n",
    "ax_tl.plot(trainer_1.train_epoch_costs, color=next(colours))\n",
    "ax_bl.plot(trainer_1.train_results['acc'], color=next(colours))\n",
    "ax_tr.plot(trainer_1.val_costs, color=next(colours))\n",
    "ax_br.plot(trainer_1.val_results['acc'], color=next(colours))\n",
    "\n",
    "test_acc_1 = acc(model_1(test_circuits_1), test_labels_1)\n",
    "#print('Test accuracy:', test_acc_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14997eaf-1016-44db-ade0-06b0eb257ad9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
