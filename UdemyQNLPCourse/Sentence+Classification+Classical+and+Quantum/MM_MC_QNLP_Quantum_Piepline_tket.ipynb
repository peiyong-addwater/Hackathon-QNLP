{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ryviqQLrsze3"
   },
   "source": [
    "**Meaning Classification with lambeq QNLP Toolkit**\n",
    "\n",
    "Quantum Pipeline Simulation\n",
    "\n",
    "This tutorial is based on - https://github.com/CQCL/lambeq/blob/main/docs/examples/quantum_pipeline_tket.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1Lxm_NHEtSgk"
   },
   "source": [
    "There are total 130 sentences in the data set where the training set has 70, development set has 30 and test set has 30. There are two kinds of sentences available which are related to either Maths or Music. This is a binary senence classification problem."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R8Ed0r8zfSwz",
    "outputId": "e2de3ea0-c329-4dd9-c5cc-2806eb0316be"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MaGjHUWsxIEg"
   },
   "source": [
    "**Installing necessary libraries**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4AcD7H1YUJDJ",
    "outputId": "46419ee5-accd-495f-babc-d897d59f4c84"
   },
   "source": [
    "! pip install lambeq"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "wDVbfH2MR5lN",
    "outputId": "9def3e3e-7cf4-43aa-ba9f-823835694316"
   },
   "source": [
    "! pip install lambeq[depccg]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vj6kcQ2jR8iR",
    "outputId": "55c225db-d862-4602-be27-5358012759a4"
   },
   "source": [
    "! depccg_en download"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "IrA9UGEFNbxQ",
    "outputId": "4926e2b1-1068-4ffa-b585-b672c8438a01"
   },
   "source": [
    "!pip install pytket-qiskit"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3ciD8V2KON7B",
    "outputId": "1c80546b-45c4-458a-d983-d3c4c1263b4e"
   },
   "source": [
    "!pip install noisyopt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c1e5vX3BvLPo"
   },
   "source": [
    "**Reading the dataset and storing it in separate variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7Z7kn_CAU4J4"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def read_data(filename):\n",
    "    labels, sentences = [], []\n",
    "    with open(filename) as f:\n",
    "        for line in f:\n",
    "            labels.append([1, 0] if line[0] == '1' else [0, 1])\n",
    "            sentences.append(line[1:].strip())\n",
    "    return np.array(labels), sentences\n",
    "\n",
    "\n",
    "train_labels, train_data = read_data('mm_mc_train_data.txt')\n",
    "dev_labels, dev_data = read_data('mm_mc_dev_data.txt')\n",
    "test_labels, test_data = read_data('mm_mc_test_data.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHJF5OrPvUWS"
   },
   "source": [
    "**Parsing the sentences and converting them into string diagrams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YJKl1OtvWudw"
   },
   "outputs": [],
   "source": [
    "from lambeq import BobcatParser\n",
    "from lambeq import TreeReader\n",
    "from discopy import grammar\n",
    "\n",
    "# reader = BobcatParser(verbose='suppress')\n",
    "reader = TreeReader()\n",
    "\n",
    "raw_train_diagrams = reader.sentences2diagrams(train_data)\n",
    "raw_dev_diagrams = reader.sentences2diagrams(dev_data)\n",
    "raw_test_diagrams = reader.sentences2diagrams(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mtJe3zRZvi2s"
   },
   "source": [
    "**String diagram rewriting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 319
    },
    "id": "n9H5oA5BXWhG",
    "outputId": "fbf41616-8af9-44e2-ab83-75751c32a0c4"
   },
   "outputs": [],
   "source": [
    "from discopy.rigid import Id\n",
    "\n",
    "\n",
    "def remove_cups(diagram):\n",
    "    # Remove cups to reduce post-selection in the circuit, for faster execution\n",
    "\n",
    "    diags = []\n",
    "    for box, offset in zip(diagram.boxes, diagram.offsets):\n",
    "        if not box.dom:  # word box\n",
    "            diags.insert(offset, box)\n",
    "        else:  # cup (the only other type of box in these diagrams)\n",
    "            i = 0\n",
    "            off = offset\n",
    "            while off != len(diags[i].cod) - 1:\n",
    "                assert off > 0\n",
    "                off -= len(diags[i].cod)\n",
    "                i += 1\n",
    "            left, right = diags[i:i+2]\n",
    "            \n",
    "            if len(left.cod) == 1:\n",
    "                new_diag = right >> (left.r.dagger() @ Id(right.cod[1:]))\n",
    "            else:\n",
    "                assert len(right.cod) == 1\n",
    "                new_diag = left >> (Id(left.cod[:-1]) @ right.l.dagger())\n",
    "\n",
    "            diags[i:i+2] = [new_diag]\n",
    "\n",
    "    assert len(diags) == 1\n",
    "    return diags[0]\n",
    "\n",
    "\n",
    "train_diagrams = [remove_cups(diagram) for diagram in raw_train_diagrams]\n",
    "dev_diagrams = [remove_cups(diagram) for diagram in raw_dev_diagrams]\n",
    "test_diagrams = [remove_cups(diagram) for diagram in raw_test_diagrams]\n",
    "\n",
    "train_diagrams[0].draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OUNUGAf0vnvY"
   },
   "source": [
    "**Conversion of each diagram into a quantum circuit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 895
    },
    "id": "SHceVH8hYkdA",
    "outputId": "85c9596c-095d-4ba3-e60d-e4d0f7d5b1b0"
   },
   "outputs": [],
   "source": [
    "from lambeq.circuit import IQPAnsatz\n",
    "from lambeq.core.types import AtomicType\n",
    "\n",
    "ansatz = IQPAnsatz({AtomicType.NOUN: 1, AtomicType.SENTENCE: 1},\n",
    "                   n_layers=1, n_single_qubit_params=3)\n",
    "\n",
    "train_circuits = [ansatz(diagram) for diagram in train_diagrams]\n",
    "dev_circuits =  [ansatz(diagram) for diagram in dev_diagrams]\n",
    "test_circuits = [ansatz(diagram) for diagram in test_diagrams]\n",
    "\n",
    "train_circuits[0].draw(figsize=(9, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Kzavy-Gv9lM"
   },
   "source": [
    "**Sorting the symbols in quantum circuits to collect the parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AHbFpH4QYqNZ"
   },
   "outputs": [],
   "source": [
    "from sympy import default_sort_key\n",
    "\n",
    "all_circuits = train_circuits + dev_circuits + test_circuits\n",
    "\n",
    "# sort the symbols since they are returned as a set\n",
    "parameters = sorted(\n",
    "    {s for circ in all_circuits for s in circ.free_symbols},\n",
    "    key=default_sort_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r3rtRH7rwJq3"
   },
   "source": [
    "**Defining the quantum simulator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bOkSNH4fYuzo"
   },
   "outputs": [],
   "source": [
    "## CONFIGURE BACKEND\n",
    "# This uses Qiskit, which requires installing `pytket-qiskit`.\n",
    "# For more information on how to use pytket with different backends, see:\n",
    "# https://cqcl.github.io/pytket/build/html/extensions/\n",
    "\n",
    "# Aer is a shots-based backend that is always available.\n",
    "\n",
    "from pytket.extensions.qiskit import AerBackend\n",
    "backend = AerBackend()\n",
    "\n",
    "## Having an IBMQ account gives access to the IBM emulator for noisy simulations:\n",
    "#\n",
    "# from pytket.extensions.qiskit import IBMQEmulatorBackend\n",
    "# backend = IBMQEmulatorBackend('PLACEHOLDER')\n",
    "#\n",
    "## To use a real device:\n",
    "#\n",
    "# from pytket.extensions.qiskit import IBMQBackend\n",
    "# backend = IBMQBackend('PLACEHOLDER')\n",
    "\n",
    "backend_config = {\n",
    "    'backend': backend,\n",
    "    'compilation': backend.default_compilation_pass(2),\n",
    "    'n_shots': 8192  # maximum recommended shots, reduces sampling error\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lfyiDBJKwO42"
   },
   "source": [
    "**Making predictions from the quantum circuits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zm8GkivxY1JT"
   },
   "outputs": [],
   "source": [
    "from discopy.quantum import Circuit, Id, Measure\n",
    "\n",
    "\n",
    "def randint(rng, low=-1 << 63, high=1 << 63-1):\n",
    "    return rng.integers(low, high)\n",
    "\n",
    "\n",
    "def normalise(predictions):\n",
    "    # apply smoothing to predictions\n",
    "    predictions = np.abs(predictions) + 1e-9\n",
    "    return predictions / predictions.sum()\n",
    "\n",
    "\n",
    "def make_pred_fn(circuits, rng):\n",
    "    measured_circuits = [c >> Id().tensor(*[Measure()] * len(c.cod)) for c in circuits]\n",
    "    circuit_fns = [c.lambdify(*parameters) for c in measured_circuits]\n",
    "\n",
    "    def predict(params):\n",
    "        outputs = Circuit.eval(*(c_fn(*params) for c_fn in circuit_fns),\n",
    "                               **backend_config, seed=randint(rng))\n",
    "        return np.array([normalise(output.array) for output in outputs])\n",
    "    return predict\n",
    "\n",
    "\n",
    "SEED = 0\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "train_pred_fn = make_pred_fn(train_circuits, rng)\n",
    "dev_pred_fn = make_pred_fn(dev_circuits, rng)\n",
    "test_pred_fn = make_pred_fn(test_circuits, rng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YMzEttH7wYYh"
   },
   "source": [
    "**Calculating cost function, accuracy and optimizing the circuit parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WeVvpdSRY561"
   },
   "outputs": [],
   "source": [
    "from noisyopt import minimizeSPSA\n",
    "\n",
    "def make_cost_fn(pred_fn, labels):\n",
    "    def cost_fn(params, **kwargs):\n",
    "        predictions = pred_fn(params)\n",
    "\n",
    "        cost = -np.sum(labels * np.log(predictions)) / len(labels)  # binary cross-entropy loss\n",
    "        costs.append(cost)\n",
    "\n",
    "        acc = np.sum(np.round(predictions) == labels) / len(labels) / 2  # half due to double-counting\n",
    "        accuracies.append(acc)\n",
    "\n",
    "        return cost\n",
    "\n",
    "    costs, accuracies = [], []\n",
    "    return cost_fn, costs, accuracies\n",
    "\n",
    "\n",
    "train_cost_fn, train_costs, train_accs = make_cost_fn(train_pred_fn, train_labels)\n",
    "dev_cost_fn, dev_costs, dev_accs = make_cost_fn(dev_pred_fn, dev_labels)\n",
    "\n",
    "x0 = np.array(rng.random(len(parameters)))\n",
    "np.random.seed(SEED)\n",
    "result = minimizeSPSA(train_cost_fn, x0=x0, a=0.2, c=0.06, niter=80, callback=dev_cost_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ar0jTfNGwv2y"
   },
   "source": [
    "**Plotting the training & development set results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "id": "gV1Ul7PcY9Cp",
    "outputId": "ca98d048-eda9-42fa-884a-c6e1b882536e"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ((ax_tl, ax_tr), (ax_bl, ax_br)) = plt.subplots(2, 2, sharex=True, sharey='row', figsize=(10, 6))\n",
    "ax_tl.set_title('Training set')\n",
    "ax_tr.set_title('Development set')\n",
    "ax_bl.set_xlabel('Iterations')\n",
    "ax_br.set_xlabel('Iterations')\n",
    "ax_bl.set_ylabel('Accuracy')\n",
    "ax_tl.set_ylabel('Loss')\n",
    "\n",
    "colours = iter(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n",
    "ax_tl.plot(train_costs[1::2], color=next(colours))  # training evaluates twice per iteration\n",
    "ax_bl.plot(train_accs[1::2], color=next(colours))   # so take every other entry\n",
    "ax_tr.plot(dev_costs, color=next(colours))\n",
    "ax_br.plot(dev_accs, color=next(colours))\n",
    "\n",
    "# print test accuracy\n",
    "test_cost_fn, _, test_accs = make_cost_fn(test_pred_fn, test_labels)\n",
    "test_cost_fn(result.x)\n",
    "print('Test accuracy:', test_accs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Lb_j0wXQZTjX"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MM_MC_QNLP_Quantum_Piepline_tket.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
