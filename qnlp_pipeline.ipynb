{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f77042f-a3da-426e-980e-044b38949914",
   "metadata": {
    "tags": []
   },
   "source": [
    "# The QNLP Pipeline for Twitter Sentiment Analysis\n",
    "## 1. Load the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3824bba-eb18-4f46-bafa-4a670c427b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "from random import shuffle\n",
    "import random\n",
    "from discopy.tensor import Tensor\n",
    "from discopy import Word\n",
    "from discopy.rigid import Functor\n",
    "from discopy import grammar\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from jax import numpy as np\n",
    "import numpy\n",
    "from lambeq import AtomicType, IQPAnsatz, remove_cups, NumpyModel, spiders_reader\n",
    "from lambeq import BobcatParser, TreeReader, cups_reader, DepCCGParser\n",
    "from lambeq import Dataset\n",
    "from lambeq import QuantumTrainer, SPSAOptimizer\n",
    "from lambeq import TketModel\n",
    "from lambeq import Rewriter\n",
    "from pytket.extensions.qiskit import AerBackend\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.options.display.max_colwidth=80\n",
    "print(os.getcwd())\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "BATCH_SIZE = 100\n",
    "EPOCHS = 100\n",
    "SEED = 0\n",
    "\n",
    "TRAIN_INDEX_RATIO = 0.06\n",
    "VAL_INDEX_RATIO = TRAIN_INDEX_RATIO + 0.01\n",
    "TEST_INDEX_RATIO = VAL_INDEX_RATIO + 0.01\n",
    "\n",
    "assert TEST_INDEX_RATIO <= 1\n",
    "\n",
    "def load_pickled_dict_to_df(filename):\n",
    "    saved_dict = pickle.load(open(filename, 'rb'))\n",
    "    df =  pd.DataFrame.from_dict(saved_dict)\n",
    "    df =  df.sample(frac=1, random_state=SEED).reset_index(drop=True)\n",
    "    sentiment = []\n",
    "    for i in df['target']:\n",
    "        if i == \"Positive\":\n",
    "            sentiment.append(1)\n",
    "        else:\n",
    "            sentiment.append(0)\n",
    "    df[\"Sentiment\"] = sentiment\n",
    "    return df\n",
    "\n",
    "cleaned_qnlp_filename = os.path.join(os.getcwd(), 'cleaned_qnlp_data.pkl')\n",
    "cleaned_lemmatized_qnlp_filename = os.path.join(os.getcwd(), 'cleaned_qnlp_data_lematize.pkl')\n",
    "cleaned_lemmatized_stemmed_qnlp_filename = os.path.join(os.getcwd(), 'cleaned_qnlp_data_stem_lematize.pkl')\n",
    "\n",
    "cleaned_qnlp = load_pickled_dict_to_df(cleaned_qnlp_filename)\n",
    "\n",
    "cleaned_lemmatized_qnlp = load_pickled_dict_to_df(cleaned_lemmatized_qnlp_filename)\n",
    "\n",
    "cleaned__lemmatized_stemmed_qnlp = load_pickled_dict_to_df(cleaned_lemmatized_stemmed_qnlp_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a7efb9-18c0-4a8d-b3c1-93c149971571",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_qnlp.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7515c83a-1b10-4162-96ac-e1809637ad5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_qnlp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9761735-1ceb-4bfa-9584-8b88773a4d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x = \"target\", data = cleaned_qnlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1b3ad8-e7aa-4045-8a9c-78dc26075823",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_lemmatized_qnlp.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc7b47f-d4cd-4694-8990-6ae7304a7757",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_lemmatized_qnlp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de851c0b-4e86-48d7-ba4e-11bd74b1bc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='target', data = cleaned_lemmatized_qnlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a635a65c-17ca-4e4d-888c-c564498bef7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned__lemmatized_stemmed_qnlp.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354d02dc-2c1d-4b8c-8242-8a6517b8a4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned__lemmatized_stemmed_qnlp.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602f278c-407a-4ffd-8b6f-2a94bca1ef00",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='target', data = cleaned__lemmatized_stemmed_qnlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d67456-d626-4fb6-bb12-ec3210a13e9c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. Train QNLP Models for Different-Preprocessed Data\n",
    "Since the limited parsing and training speed using on the CPU, we'll only use a fraction of our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50766c20-c2f8-4fc2-974e-55c8e58fe93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parser = BobcatParser(verbose='text')\n",
    "# parser = DepCCGParser(root_cats=['S[dcl]'])\n",
    "parser = cups_reader\n",
    "NUM_DATA = 4084\n",
    "\n",
    "loss = lambda y_hat, y: -np.sum(y * np.log(y_hat)) / len(y)  # binary cross-entropy loss\n",
    "acc = lambda y_hat, y: np.sum(np.round(y_hat) == y) / len(y) / 2  # half due to double-counting\n",
    "rewriter = Rewriter(['prepositional_phrase', 'determiner', 'auxiliary', 'connector', \n",
    "                         'coordination', 'object_rel_pronoun', 'subject_rel_pronoun',\n",
    "                        'postadverb', 'preadverb'])\n",
    "def rewrite(diagram):\n",
    "    # diagram = rewriter(diagram)\n",
    "    return remove_cups(diagram)\n",
    "\n",
    "def create_diagrams_and_labels(total_df):\n",
    "    total_text = total_df['data'].tolist()\n",
    "    total_labels = total_df[\"Sentiment\"].tolist()\n",
    "    total_labels = [[t, 1-t] for t in total_labels] # [1, 0] for positive, [0, 1] for negative\n",
    "    train_diagrams = parser.sentences2diagrams(total_text[:round(NUM_DATA*TRAIN_INDEX_RATIO)])\n",
    "    train_labels = total_labels[:round(NUM_DATA*TRAIN_INDEX_RATIO)]\n",
    "    dev_diagrams = parser.sentences2diagrams(total_text[round(NUM_DATA*TRAIN_INDEX_RATIO):round(NUM_DATA*VAL_INDEX_RATIO)])\n",
    "    dev_labels = total_labels[round(NUM_DATA*TRAIN_INDEX_RATIO):round(NUM_DATA*VAL_INDEX_RATIO)]\n",
    "    test_diagrams = parser.sentences2diagrams(total_text[round(NUM_DATA*VAL_INDEX_RATIO):round(NUM_DATA*TEST_INDEX_RATIO)])\n",
    "    test_labels = total_labels[round(NUM_DATA*VAL_INDEX_RATIO):round(NUM_DATA*TEST_INDEX_RATIO)]\n",
    "    \n",
    "    return train_diagrams, train_labels, dev_diagrams, dev_labels, test_diagrams, test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c0bcd7-f858-4220-b075-3152bbf85f7c",
   "metadata": {},
   "source": [
    "### 2.1 Data without Lemmatization or Stemming\n",
    "#### 2.1.1 Create diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f9920d-de6f-4410-809c-2c83e7dac786",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "raw_train_diagrams_1, train_labels_1, raw_dev_diagrams_1, dev_labels_1, raw_test_diagrams_1, test_labels_1 = create_diagrams_and_labels(cleaned_qnlp)\n",
    "print(len(raw_train_diagrams_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278401ec-572d-4e40-aa44-0df5663944ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar.draw(raw_train_diagrams_1[8],figsize=(12,3), fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f23dd5a-d9ae-42af-8d49-eeae1b447586",
   "metadata": {},
   "source": [
    "#### 2.1.2 Simplify the diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055c1f6c-1a18-47b7-8b9f-02d45f9d5f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_diagrams_1 = [rewrite(diagram) for diagram in raw_train_diagrams_1]\n",
    "dev_diagrams_1 = [rewrite(diagram) for diagram in raw_dev_diagrams_1]\n",
    "test_diagrams_1 = [rewrite(diagram) for diagram in raw_test_diagrams_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2e5e72-2a43-4de2-93fc-88f9b890511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_diagrams_1[8].draw(figsize=(6,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c33c912-81e7-4a98-ad27-01ecb112dc33",
   "metadata": {},
   "source": [
    "#### 2.1.3 Create circuits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23573aa4-3a07-43d0-b1b4-2e6c6b10b244",
   "metadata": {},
   "outputs": [],
   "source": [
    "ansatz_1 = IQPAnsatz({AtomicType.NOUN: 1, AtomicType.SENTENCE: 1, AtomicType.PREPOSITIONAL_PHRASE: 1, AtomicType.NOUN_PHRASE:1, AtomicType.CONJUNCTION:1}, n_layers=1, n_single_qubit_params=3)\n",
    "train_circuits_1 = [ansatz_1(diagram) for diagram in train_diagrams_1]\n",
    "dev_circuits_1 =  [ansatz_1(diagram) for diagram in dev_diagrams_1]\n",
    "test_circuits_1 = [ansatz_1(diagram) for diagram in test_diagrams_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba0503c-1561-4f55-84e3-4eb9738079cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_circuits_1[8].draw(figsize=(9, 12))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b774c35-5065-4cae-bcfd-ecf1e2b29c4e",
   "metadata": {},
   "source": [
    "#### 2.1.4 Parameterise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37bf884-8e1f-4f47-b2b0-047708bbe52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_circuits_1 = train_circuits_1 + dev_circuits_1 + test_circuits_1\n",
    "backend = AerBackend()\n",
    "backend_config = {\n",
    "    'backend': backend,\n",
    "    'compilation': backend.default_compilation_pass(2),\n",
    "    'shots': 2048\n",
    "}\n",
    "model_1 = NumpyModel.from_diagrams(all_circuits_1, use_jit=True)\n",
    "# model_1 = TketModel.from_diagrams(all_circuits_1, backend_config=backend_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3bcb48-cf2a-46dd-96ca-1b4b46646a42",
   "metadata": {},
   "source": [
    "#### 2.1.5 Initialize trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7468b472-f23e-47fb-887c-069334944174",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_1 = QuantumTrainer(\n",
    "    model_1,\n",
    "    loss_function=loss,\n",
    "    epochs=EPOCHS,\n",
    "    optimizer=SPSAOptimizer,\n",
    "    optim_hyperparams={'a': 0.2, 'c': 0.06, 'A':0.01*EPOCHS},\n",
    "    evaluate_functions={'acc': acc},\n",
    "    evaluate_on_train=True,\n",
    "    verbose = 'text',\n",
    "    seed=0\n",
    ")\n",
    "train_dataset_1 = Dataset(\n",
    "            train_circuits_1,\n",
    "            train_labels_1,\n",
    "            batch_size=BATCH_SIZE)\n",
    "\n",
    "val_dataset_1 = Dataset(dev_circuits_1, dev_labels_1, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013379f2-1532-414f-9fe8-c2d751367750",
   "metadata": {},
   "source": [
    "#### 2.1.6 Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d55858d6-b168-4482-a06b-f6a13003e391",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer_1.fit(train_dataset_1, val_dataset_1, logging_step=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73e1171-7877-40c5-ae59-c8822c5689c8",
   "metadata": {},
   "source": [
    "#### 2.1.7 Show Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8670eb81-c4c8-43c5-ab8a-c78d7f37fd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax_tl, ax_tr), (ax_bl, ax_br)) = plt.subplots(2, 2, sharex=True, sharey='row', figsize=(12, 8))\n",
    "ax_tl.set_title('Training set')\n",
    "ax_tr.set_title('Development set')\n",
    "ax_bl.set_xlabel('Iterations')\n",
    "ax_br.set_xlabel('Iterations')\n",
    "ax_bl.set_ylabel('Accuracy')\n",
    "ax_tl.set_ylabel('Loss')\n",
    "\n",
    "colours = iter(plt.rcParams['axes.prop_cycle'].by_key()['color'])\n",
    "ax_tl.plot(trainer_1.train_epoch_costs, color=next(colours))\n",
    "ax_bl.plot(trainer_1.train_results['acc'], color=next(colours))\n",
    "ax_tr.plot(trainer_1.val_costs, color=next(colours))\n",
    "ax_br.plot(trainer_1.val_results['acc'], color=next(colours))\n",
    "\n",
    "test_acc_1 = acc(model_1(test_circuits_1), test_labels_1)\n",
    "print('Test accuracy:', test_acc_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170651eb-d76f-4471-a896-d03d6c11809f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
